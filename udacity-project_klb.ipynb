{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "gather": {
     "logged": 1598275788035
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: quick-starts-ws-127749\n",
      "Azure region: southcentralus\n",
      "Subscription id: 3ec87f2b-33cf-4aed-b36f-750175813524\n",
      "Resource group: aml-quickstarts-127749\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "from azureml.core.run import Run\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "from azureml.core import Workspace, Dataset\n",
    "from azureml.core import Workspace,ScriptRunConfig,Experiment, Run\n",
    "\n",
    "ws = Workspace(subscription_id=\"3ec87f2b-33cf-4aed-b36f-750175813524\",\n",
    "                  resource_group=\"aml-quickstarts-127749\",\n",
    "                  workspace_name=\"quick-starts-ws-127749\")\n",
    "exp = Experiment(workspace=ws, name=\"udacity-project-hp\")\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "run = exp.start_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598275788675
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n",
      "DeletingCurrent provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# TODO: Create compute cluster\n",
    "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\n",
    "# max_nodes should be no greater than 4.\n",
    "\n",
    "\n",
    "   # Choose a name for your CPU cluster\n",
    "cpu_cluster_name = \"cpu-cluster\"\n",
    "\n",
    "   # Verify that cluster does not exist already\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
    "                                                              max_nodes=4)\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "cpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598275789986
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.train.dnn import TensorFlow\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform, normal, choice\n",
    "import os,shutil\n",
    "\n",
    "# Specify parameter sampler\n",
    "ps = RandomParameterSampling( {\n",
    "        '--C': choice(0,0.25,0.5,1),\n",
    "        '--max_iter': choice(10,50,500,1000)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Specify a Policy\n",
    "early_termination_policy = BanditPolicy(slack_factor = 0.15, evaluation_interval=2)\n",
    "\n",
    "if \"training\" not in os.listdir():\n",
    "    os.mkdir(\"./training\")\n",
    "\n",
    "script_folder = \"./training\"    \n",
    "    \n",
    "# Reference: lesson 6.3: copying the training file into the script folder\n",
    "shutil.copy('./train.py', script_folder)\n",
    "    \n",
    "script_params={\n",
    "    '--datastore-dir': ws.get_default_datastore().as_mount(),\n",
    "}\n",
    "# Create a SKLearn estimator for use with train.py\n",
    "sk_estimator = SKLearn(source_directory='training', \n",
    "                     script_params=script_params,\n",
    "                    compute_target=cpu_cluster,\n",
    "                    entry_script='train.py',\n",
    "                    pip_packages=['joblib']\n",
    "                   )\n",
    "\n",
    "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
    "hyperdrive_run_config = HyperDriveConfig(estimator = sk_estimator, \n",
    "                                            hyperparameter_sampling = ps, \n",
    "                                            policy = early_termination_policy,\n",
    "                                            primary_metric_name = \"Accuracy\",\n",
    "                                            primary_metric_goal = PrimaryMetricGoal.MAXIMIZE,\n",
    "                                            max_total_runs = 2,\n",
    "                                            max_concurrent_runs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
    "\n",
    "hd_run = exp.submit(hyperdrive_run_config)\n",
    "RunDetails(Run(exp, hd_run.id)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gather": {
     "logged": 1598276310862
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_metrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-19da46130557>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbest_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhd_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_run_by_primary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbest_run_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mparameter_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'runDefinition'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arguments'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_metrics'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# Get your best run and save the model from that run.\n",
    "\n",
    "best_run = hd_run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "parameter_values = best_run.get_details()['runDefinition']['arguments']\n",
    "\n",
    "print('Best Run Id: ', best_run.id)\n",
    "print('\\n Accuracy:', best_run_metrics['Accuracy'])\n",
    "print('\\n learning rate:',parameter_values[3])\n",
    "print('\\n keep probability:',parameter_values[5])\n",
    "print('\\n batch size:',parameter_values[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "\n",
    "# Create TabularDataset using TabularDatasetFactory\n",
    "# Data is available at: \n",
    "# \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
    "from azureml.core import Dataset\n",
    "exp_automl = Experiment(workspace=ws, name=\"udacity-project-automl\")\n",
    "config = ScriptRunConfig(source_directory='training', script='train.py', compute_target='cpu-cluster')\n",
    "data = \"https://udacitystorage.blob.core.windows.net/udacity/bankmarketing_train.csv\"\n",
    "ds = Dataset.Tabular.from_delimited_files(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1598275726969
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading data_train/data_train.csv\n",
      "Uploaded data_train/data_train.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    }
   ],
   "source": [
    "from train import clean_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    " \n",
    "x, y = clean_data(ds)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y)\n",
    "data_train = pd.concat([x_train,y_train], axis=1)\n",
    "\n",
    "os.makedirs('data_train', exist_ok=True)\n",
    "\n",
    "local_path = './data_train/data_train.csv'\n",
    "data_train.to_csv(local_path)\n",
    "\n",
    "# upload the local file to a datastore on the cloud\n",
    "workspace = Workspace(ws.subscription_id, ws.resource_group, ws.name)\n",
    "\n",
    "# get the datastore to upload prepared data\n",
    "datastore = ws.get_default_datastore()\n",
    "\n",
    "# upload the local file from src_dir to the target_path in datastore\n",
    "datastore.upload(src_dir='data_train', target_path='data_train')\n",
    "\n",
    "# create a dataset referencing the cloud location\n",
    "data_train = Dataset.Tabular.from_delimited_files(path = [(datastore, ('data_train/data_train.csv'))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1598275665403
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "# Set parameters for AutoMLConfig\n",
    "# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n",
    "# If you wish to run the experiment longer, you will need to run this notebook in your own\n",
    "# Azure tenant, which will incur personal costs.\n",
    "automl_config = AutoMLConfig(\n",
    "    experiment_timeout_minutes=30,\n",
    "    task='classification',\n",
    "    primary_metric='accuracy',\n",
    "    training_data=data_train,\n",
    "    label_column_name=\"y\",\n",
    "    n_cross_validations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine\n",
      "Parent Run ID: AutoML_21761394-f8a7-49c8-9a94-e158489fcd1c\n",
      "\n",
      "Current status: DatasetEvaluation. Gathering dataset statistics.\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: DatasetFeaturization. Beginning to fit featurizers and featurize the dataset.\n",
      "Current status: DatasetFeaturizationCompleted. Completed fit featurizers and featurizing the dataset.\n",
      "Current status: DatasetBalancing. Performing class balancing sweeping\n",
      "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         Class balancing detection\n",
      "STATUS:       ALERTED\n",
      "DESCRIPTION:  To decrease model bias, please cancel the current run and fix balancing problem.\n",
      "              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n",
      "DETAILS:      Imbalanced data can lead to a falsely perceived positive effect of a model's accuracy because the input data has bias towards one class.\n",
      "+---------------------------------+---------------------------------+--------------------------------------+\n",
      "|Size of the smallest class       |Name/Label of the smallest class |Number of samples in the training data|\n",
      "+=================================+=================================+======================================+\n",
      "|2737                             |1                                |24712                                 |\n",
      "+---------------------------------+---------------------------------+--------------------------------------+\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         Missing feature values imputation\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  No feature missing values were detected in the training data.\n",
      "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         High cardinality feature detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
      "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   MaxAbsScaler LightGBM                          0:00:33       0.9177    0.9177\n",
      "         1   MaxAbsScaler XGBoostClassifier                 0:00:38       0.9170    0.9177\n",
      "         2   MaxAbsScaler RandomForest                      0:00:33       0.8939    0.9177\n",
      "         3   MaxAbsScaler RandomForest                      0:00:43       0.8892    0.9177\n",
      "         4   MaxAbsScaler SGD                               0:00:33       0.8603    0.9177\n",
      "         5   MaxAbsScaler SGD                               0:00:33       0.9079    0.9177\n",
      "         6   MaxAbsScaler ExtremeRandomTrees                0:00:37       0.9003    0.9177\n",
      "         7   MaxAbsScaler ExtremeRandomTrees                0:00:39       0.8999    0.9177\n",
      "         8   MaxAbsScaler ExtremeRandomTrees                0:00:41       0.9001    0.9177\n",
      "         9   MaxAbsScaler ExtremeRandomTrees                0:00:40       0.7752    0.9177\n",
      "        10   MaxAbsScaler SGD                               0:00:38       0.9047    0.9177\n",
      "        11   MaxAbsScaler SGD                               0:00:33       0.9045    0.9177\n",
      "        12   MaxAbsScaler RandomForest                      0:00:32       0.8905    0.9177\n",
      "        13   StandardScalerWrapper ExtremeRandomTrees       0:00:40       0.8892    0.9177\n",
      "        14   MaxAbsScaler RandomForest                      0:00:34       0.7518    0.9177\n",
      "        15   MaxAbsScaler SGD                               0:00:38       0.8538    0.9177\n",
      "        16   MaxAbsScaler RandomForest                      0:00:41       0.8892    0.9177\n",
      "        17   MaxAbsScaler ExtremeRandomTrees                0:00:45       0.8991    0.9177\n",
      "        18   SparseNormalizer ExtremeRandomTrees            0:00:44       0.7218    0.9177\n",
      "        19   MaxAbsScaler SGD                               0:00:41       0.9061    0.9177\n",
      "        20   "
     ]
    }
   ],
   "source": [
    "# Submit your automl run\n",
    "experiment_name = 'automl-classification'\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and save your best automl model.\n",
    "best_run, fitted_model = run.get_output()\n",
    "print(best_run)\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cpu_cluster.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
